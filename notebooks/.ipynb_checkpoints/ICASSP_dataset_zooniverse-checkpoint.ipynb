{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikiskin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# Notification\n",
    "import time\n",
    "from IPython.display import Audio\n",
    "sound_file = \"beep.wav\"\n",
    "# File IO\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "# Deep learning\n",
    "# Keras-related imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Convolution1D, MaxPooling2D, Convolution2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import RemoteMonitor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# Result processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0: Perform feature transform, save data\n",
    "\n",
    "This section is used to create the $(\\mathbf{X},y)$ training set with feature choice parameterised by either `{'log-mel', 'mfcc'}`. Librosa is used to extract the features, and has further support for any features one may wish to choose.\n",
    "\n",
    "Once this section has been run once, the user is advised to skip to **Section 1** which deals with performing a baseline classification using a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterise feature transform here. The default is to use log-mel features, but the user may implement any choice\n",
    "# or use the raw time-series as preferred \n",
    "\n",
    "feature_type = 'log-mel'  # Select from {'log-mel', 'mfcc'}\n",
    "\n",
    "\n",
    "win_len = 0.1  # Window length of feature\n",
    "n_mels = 128  # Number of log-mel coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the root of the processed 1 second audio chunks, where votes have been aggregated already\n",
    "# This path is relative, and should by default point to the correct location\n",
    "\n",
    "wav_root = '../audio_data_1_sec/'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the label information contained in the resolved 1 second chunks, with votes {'yes', 'no', 'not_sure'}\n",
    "\n",
    "df = pd.read_csv('../labels/audio_labels_1_sec.csv',  header=None, names=[\"path\", \"yes\", \"no\", \"not_sure\",\"subject_set\"])\n",
    "df['path'] = df['path'].astype(str) + '.wav'\n",
    "\n",
    "\n",
    "# Create the y vector by treating 'not_sure' as 0.5, 'yes' as 1.0, 'no' as 0.0 and average\n",
    "df['res'] = (df['yes'].astype(int)*1 + df['not_sure'].astype(int)*0.5) / (df['yes'] + df['no'] + df['not_sure']) >= 0.5\n",
    "total_audio_n = len(df.index.values.tolist())\n",
    "\n",
    "y = np.zeros((total_audio_n, 2))\n",
    "\n",
    "y[:,1] = np.array(np.array(df['res']).astype(int)).astype(int)\n",
    "y[:,0] = 1-y[:,1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ikiskin/GDrive/AIMSCDT/PhD/Code/ICASSP/audio_data_1_sec/47650002.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3be0b9544ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialise empty X matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load one spectrogram file to calculate dimensions of entire set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeature_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log-mel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ikiskin/GDrive/AIMSCDT/PhD/Code/ICASSP/audio_data_1_sec/47650002.wav'"
     ]
    }
   ],
   "source": [
    "# Initialise dimensions for feature transformation\n",
    "\n",
    "nfft = int(win_len * 8000)\n",
    "wav_path = wav_root + df[\"path\"]\n",
    "\n",
    "# Initialise empty X matrix\n",
    "wav, fs = librosa.load(wav_path.iloc[0],sr=None)  # Load one spectrogram file to calculate dimensions of entire set\n",
    "\n",
    "if feature_type == 'log-mel':    \n",
    "    spec = librosa.feature.melspectrogram(y=wav, sr=fs, n_mels=n_mels, n_fft=nfft*4, hop_length=nfft)\n",
    "             \n",
    "elif feature_type == 'mfcc':\n",
    "    spec = librosa.feature.mfcc(y=wav, sr=fs, n_mfcc=13, n_fft=nfft*4, hop_length=nfft)\n",
    "    \n",
    "l_spec = np.shape(spec)[1]  # Length of the spectral representation for each 2 second chunk\n",
    "h_spec = np.shape(spec)[0]  # This is also n_mels\n",
    "spec_matrix = np.zeros([n_samples, h_spec, l_spec])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../audio_data/audio_1sec/audio_1sec/47660000.wav'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_path.iloc[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40    ../audio_data/audio_1sec/audio_1sec/47650045.wav\n",
       "41    ../audio_data/audio_1sec/audio_1sec/47650046.wav\n",
       "42    ../audio_data/audio_1sec/audio_1sec/47650047.wav\n",
       "43    ../audio_data/audio_1sec/audio_1sec/47650048.wav\n",
       "44    ../audio_data/audio_1sec/audio_1sec/47650049.wav\n",
       "45    ../audio_data/audio_1sec/audio_1sec/47650050.wav\n",
       "46    ../audio_data/audio_1sec/audio_1sec/47650051.wav\n",
       "47    ../audio_data/audio_1sec/audio_1sec/47660000.wav\n",
       "48    ../audio_data/audio_1sec/audio_1sec/47660001.wav\n",
       "49    ../audio_data/audio_1sec/audio_1sec/47660002.wav\n",
       "50    ../audio_data/audio_1sec/audio_1sec/47660003.wav\n",
       "51    ../audio_data/audio_1sec/audio_1sec/47660005.wav\n",
       "52    ../audio_data/audio_1sec/audio_1sec/47660006.wav\n",
       "53    ../audio_data/audio_1sec/audio_1sec/47660007.wav\n",
       "54    ../audio_data/audio_1sec/audio_1sec/47660008.wav\n",
       "55    ../audio_data/audio_1sec/audio_1sec/47660009.wav\n",
       "56    ../audio_data/audio_1sec/audio_1sec/47660010.wav\n",
       "57    ../audio_data/audio_1sec/audio_1sec/47660012.wav\n",
       "58    ../audio_data/audio_1sec/audio_1sec/47660014.wav\n",
       "59    ../audio_data/audio_1sec/audio_1sec/47660015.wav\n",
       "60    ../audio_data/audio_1sec/audio_1sec/47660016.wav\n",
       "61    ../audio_data/audio_1sec/audio_1sec/47660017.wav\n",
       "62    ../audio_data/audio_1sec/audio_1sec/47660018.wav\n",
       "63    ../audio_data/audio_1sec/audio_1sec/47660019.wav\n",
       "64    ../audio_data/audio_1sec/audio_1sec/47660020.wav\n",
       "65    ../audio_data/audio_1sec/audio_1sec/47660021.wav\n",
       "66    ../audio_data/audio_1sec/audio_1sec/47660022.wav\n",
       "67    ../audio_data/audio_1sec/audio_1sec/47660023.wav\n",
       "68    ../audio_data/audio_1sec/audio_1sec/47660024.wav\n",
       "69    ../audio_data/audio_1sec/audio_1sec/47660026.wav\n",
       "70    ../audio_data/audio_1sec/audio_1sec/47660027.wav\n",
       "71    ../audio_data/audio_1sec/audio_1sec/47660028.wav\n",
       "72    ../audio_data/audio_1sec/audio_1sec/47660030.wav\n",
       "73    ../audio_data/audio_1sec/audio_1sec/47660031.wav\n",
       "74    ../audio_data/audio_1sec/audio_1sec/47660032.wav\n",
       "75    ../audio_data/audio_1sec/audio_1sec/47660033.wav\n",
       "76    ../audio_data/audio_1sec/audio_1sec/47660034.wav\n",
       "77    ../audio_data/audio_1sec/audio_1sec/47660035.wav\n",
       "78    ../audio_data/audio_1sec/audio_1sec/47660036.wav\n",
       "79    ../audio_data/audio_1sec/audio_1sec/47660037.wav\n",
       "80    ../audio_data/audio_1sec/audio_1sec/47660038.wav\n",
       "81    ../audio_data/audio_1sec/audio_1sec/47660039.wav\n",
       "82    ../audio_data/audio_1sec/audio_1sec/47660040.wav\n",
       "83    ../audio_data/audio_1sec/audio_1sec/47660041.wav\n",
       "84    ../audio_data/audio_1sec/audio_1sec/47660042.wav\n",
       "85    ../audio_data/audio_1sec/audio_1sec/47660043.wav\n",
       "86    ../audio_data/audio_1sec/audio_1sec/47660044.wav\n",
       "87    ../audio_data/audio_1sec/audio_1sec/47660045.wav\n",
       "88    ../audio_data/audio_1sec/audio_1sec/47660046.wav\n",
       "89    ../audio_data/audio_1sec/audio_1sec/47660047.wav\n",
       "90    ../audio_data/audio_1sec/audio_1sec/47660048.wav\n",
       "91    ../audio_data/audio_1sec/audio_1sec/47660049.wav\n",
       "92    ../audio_data/audio_1sec/audio_1sec/47660051.wav\n",
       "93    ../audio_data/audio_1sec/audio_1sec/47660052.wav\n",
       "94    ../audio_data/audio_1sec/audio_1sec/47670000.wav\n",
       "95    ../audio_data/audio_1sec/audio_1sec/47670002.wav\n",
       "96    ../audio_data/audio_1sec/audio_1sec/47670003.wav\n",
       "97    ../audio_data/audio_1sec/audio_1sec/47670004.wav\n",
       "98    ../audio_data/audio_1sec/audio_1sec/47670005.wav\n",
       "99    ../audio_data/audio_1sec/audio_1sec/47670006.wav\n",
       "Name: path, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_path[40:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iteration 0 0 939\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ikiskin/Documents/PythonTesting/audio_data/audio_1sec/audio_1sec/47660000.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-055f4801a0e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Create X matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log-mel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         spec_matrix[i] = librosa.feature.melspectrogram(y=audio_file,\n",
      "\u001b[0;32m/Applications/anaconda/envs/py36/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py36/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrawread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawAudioFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/envs/py36/lib/python3.6/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ikiskin/Documents/PythonTesting/audio_data/audio_1sec/audio_1sec/47660000.wav'"
     ]
    }
   ],
   "source": [
    "# Perform feature transformation and store result in pre-allocated spec_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(0, total_audio_n):\n",
    "#     if count[i] == 1:\n",
    "    print(i)\n",
    "        \n",
    "        # Create X matrix\n",
    "    audio_file, fs = librosa.load(wav_path.loc[i],sr=None)\n",
    "    if feature_type == 'log-mel':\n",
    "        spec_matrix[i] = librosa.feature.melspectrogram(y=audio_file,\n",
    "                                                        sr=fs, n_mels=n_mels, n_fft=nfft*4, hop_length=nfft)\n",
    "\n",
    "    elif feature_type == 'mfcc':\n",
    "        spec_matrix[i] = librosa.feature.mfcc(y=audio_file,\n",
    "                                                        sr=fs, n_mfcc=13, n_fft=nfft*4, hop_length=nfft)            \n",
    "        \n",
    "    if i%1000 == 0:\n",
    "        time_used = time.time()-start_time\n",
    "        time_total = time_used * total_audio_n / (i+1)\n",
    "        \n",
    "        print('Iteration', str(i), \"%i\"%(time_used), \"%i\"%(time_total))\n",
    "\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files with file_name if not in path\n",
    "\n",
    "file_names = ['data_log-melnot_sure_single_into_0_5.h5', 'label_log-melnot_sure_single_into_0_5.h5']\n",
    "\n",
    "for file_name in file_names:\n",
    "    if not os.path.isfile('../proc_data/' + file_name):\n",
    "        hf = h5py.File('../proc_data/data_' + feature_type + 'not_sure_single_into_0_5.h5', 'w')\n",
    "        hf.create_dataset('../proc_data/data_' + feature_type + '_majority_labels_not_sure_single_into_0_5',\n",
    "                          data=spec_matrix)\n",
    "        hf.close()\n",
    "        \n",
    "        hf = h5py.File('../proc_data/label_' + feature_type + 'not_sure_single_into_0_5.h5', 'w')\n",
    "        hf.create_dataset('../proc_data/label_' + feature_type + '_majority_labels_not_sure_single_into_0_5', data=y)\n",
    "        hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Load and classify\n",
    "\n",
    "If the feature transform has already been performed and the data is saved in `proc_data`, load the data in the cell below and perform classification as outlined by the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "save_name = 'not_sure_single_into_0_5'\n",
    "\n",
    "hf = h5py.File('../proc_data/data_' + feature_type + save_name + '.h5', 'r')\n",
    "spec_matrix_read = np.array(hf.get('../proc_data/data_' + feature_type + '_majority_labels_' + save_name))\n",
    "hf.close()\n",
    "\n",
    "hf = h5py.File('../proc_data/label_' + feature_type + save_name + '.h5', 'r')\n",
    "y = np.array(hf.get('../proc_data/label_' + feature_type + '_majority_labels_' + save_name))\n",
    "hf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load functions for results processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dB\n",
    "\n",
    "spec_matrix_db = np.zeros_like(spec_matrix_read)\n",
    "\n",
    "for i, spec in enumerate(spec_matrix_read):\n",
    "    spec_matrix_db[i] = librosa.power_to_db(spec,ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Convolutional Neural Network\n",
    "\n",
    "First, the data is split tenfold using `sklearn`'s `train_test_split` with the random states given in the `random_state` vector.\n",
    "\n",
    "The neural network cross-entropy weights are set in the dictionary `class_weight`, with the key `0` referring to the noise class, and `1` referring to the mosquito class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 5s 87us/step - loss: 1.0225 - acc: 0.7766\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9595 - acc: 0.8093\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9407 - acc: 0.8162\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9302 - acc: 0.8232\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 5s 86us/step - loss: 0.9241 - acc: 0.8273\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 5s 89us/step - loss: 0.9149 - acc: 0.8290\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9163 - acc: 0.8328\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9111 - acc: 0.8375\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.9127 - acc: 0.8351\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9082 - acc: 0.8338\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9049 - acc: 0.8363\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.9067 - acc: 0.8360\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 5s 86us/step - loss: 0.9070 - acc: 0.8408\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 5s 84us/step - loss: 0.9053 - acc: 0.8414\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9037 - acc: 0.8401\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9065 - acc: 0.8447\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9044 - acc: 0.8428\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9062 - acc: 0.8416\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9036 - acc: 0.8447\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9011 - acc: 0.8478\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9025 - acc: 0.8448\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9021 - acc: 0.8427\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9019 - acc: 0.8509\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8960 - acc: 0.8496\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9053 - acc: 0.8477\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.9031 - acc: 0.8530\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8888 - acc: 0.8490\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8948 - acc: 0.8478\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 5s 86us/step - loss: 0.8939 - acc: 0.8430\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8922 - acc: 0.8479\n",
      "10 0.4603332926585923 0.8343793982341974\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 1.0149 - acc: 0.7742\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9502 - acc: 0.8144\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9334 - acc: 0.8209\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9251 - acc: 0.8300\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9189 - acc: 0.8295\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9152 - acc: 0.8365\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9095 - acc: 0.8389\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9102 - acc: 0.8389\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 5s 86us/step - loss: 0.9069 - acc: 0.8406\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.9021 - acc: 0.8448\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.8997 - acc: 0.8441\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9021 - acc: 0.8473\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.9015 - acc: 0.8466\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8994 - acc: 0.8489\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.9023 - acc: 0.8466\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9005 - acc: 0.8492\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.9008 - acc: 0.8536\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8977 - acc: 0.8539\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8980 - acc: 0.8552\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8958 - acc: 0.8559\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8973 - acc: 0.8598\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8963 - acc: 0.8558\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9004 - acc: 0.8580\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8928 - acc: 0.8555\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8978 - acc: 0.8594\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8912 - acc: 0.8584\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8939 - acc: 0.8634\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8894 - acc: 0.8574\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8919 - acc: 0.8500\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8926 - acc: 0.8482\n",
      "20 0.44861781865470585 0.872760470163156\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 1.0114 - acc: 0.7761\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9483 - acc: 0.8148\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9288 - acc: 0.8191\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9176 - acc: 0.8290\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9115 - acc: 0.8328\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.9042 - acc: 0.8375\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9041 - acc: 0.8405\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8971 - acc: 0.8391\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8956 - acc: 0.8426\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.8943 - acc: 0.8466\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 0.8920 - acc: 0.8481\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.8918 - acc: 0.8436\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8928 - acc: 0.8469\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8877 - acc: 0.8470\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8850 - acc: 0.8517\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8859 - acc: 0.8493\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8863 - acc: 0.8527\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8817 - acc: 0.8558\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8833 - acc: 0.8559\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8824 - acc: 0.8524\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8773 - acc: 0.8580\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8825 - acc: 0.8569\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8747 - acc: 0.8588\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8760 - acc: 0.8569\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8762 - acc: 0.8606\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8790 - acc: 0.8540\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8694 - acc: 0.8541\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8699 - acc: 0.8504\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8689 - acc: 0.8479\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8700 - acc: 0.8453\n",
      "30 0.42711221823301804 0.8404655939837353\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 1.0170 - acc: 0.7773\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9434 - acc: 0.8159\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9257 - acc: 0.8242\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9101 - acc: 0.8328\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9071 - acc: 0.8372\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.9038 - acc: 0.8398\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9009 - acc: 0.8432\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8992 - acc: 0.8430\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8952 - acc: 0.8467\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8965 - acc: 0.8454\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8925 - acc: 0.8461\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8909 - acc: 0.8494\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8888 - acc: 0.8511\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8890 - acc: 0.8525\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8863 - acc: 0.8527\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8834 - acc: 0.8507\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8822 - acc: 0.8544\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8826 - acc: 0.8529\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8798 - acc: 0.8571\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8836 - acc: 0.8575\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8763 - acc: 0.8507\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8759 - acc: 0.8509\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8724 - acc: 0.8498\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.8731 - acc: 0.8480\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8723 - acc: 0.8466\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8719 - acc: 0.8436\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8693 - acc: 0.8395\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8676 - acc: 0.8398\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8667 - acc: 0.8420\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.8724 - acc: 0.8390\n",
      "40 0.4283712264284293 0.8440031952550346\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 1.0187 - acc: 0.7725\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9534 - acc: 0.8062\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9371 - acc: 0.8181\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9240 - acc: 0.8236\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9216 - acc: 0.8293\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9140 - acc: 0.8333\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9152 - acc: 0.8339\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9082 - acc: 0.8353\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9115 - acc: 0.8383\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9132 - acc: 0.8379\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9121 - acc: 0.8371\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9100 - acc: 0.8397\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9070 - acc: 0.8418\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9073 - acc: 0.8437\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9088 - acc: 0.8427\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9068 - acc: 0.8439\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.9062 - acc: 0.8414\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9075 - acc: 0.8436\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.9078 - acc: 0.8454\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9048 - acc: 0.8507\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9043 - acc: 0.8498\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9060 - acc: 0.8445\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9025 - acc: 0.8479\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 75us/step - loss: 0.9027 - acc: 0.8459\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9032 - acc: 0.8423\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 0.9003 - acc: 0.8415\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9008 - acc: 0.8415\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8972 - acc: 0.8479\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8957 - acc: 0.8480\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8999 - acc: 0.8505\n",
      "50 0.48331617024150814 0.8577351744120815\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 1.0146 - acc: 0.7753\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9434 - acc: 0.8184\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9272 - acc: 0.8245\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9173 - acc: 0.8333\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9105 - acc: 0.8332\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9060 - acc: 0.8392\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9047 - acc: 0.8387\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8994 - acc: 0.8439\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8983 - acc: 0.8443\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8962 - acc: 0.8459\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8990 - acc: 0.8474\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8952 - acc: 0.8534\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8937 - acc: 0.8494\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8882 - acc: 0.8534\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8898 - acc: 0.8547\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8896 - acc: 0.8546\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8844 - acc: 0.8600\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8846 - acc: 0.8627\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8885 - acc: 0.8641\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8826 - acc: 0.8669\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8810 - acc: 0.8654\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8782 - acc: 0.8649\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8849 - acc: 0.8568\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8817 - acc: 0.8557\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8757 - acc: 0.8522\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8759 - acc: 0.8514\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8780 - acc: 0.8550\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8704 - acc: 0.8514\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8716 - acc: 0.8504\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8645 - acc: 0.8509\n",
      "60 0.4933593779764912 0.8462094412156875\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 5s 87us/step - loss: 1.0214 - acc: 0.7726\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9492 - acc: 0.8104\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.9337 - acc: 0.8184\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9221 - acc: 0.8227\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9122 - acc: 0.8290\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9074 - acc: 0.8353\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9072 - acc: 0.8347\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9065 - acc: 0.8375\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9024 - acc: 0.8392\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9015 - acc: 0.8399\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8970 - acc: 0.8428\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8974 - acc: 0.8461\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8979 - acc: 0.8445\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.8936 - acc: 0.8487\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8945 - acc: 0.8517\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 84us/step - loss: 0.8924 - acc: 0.8499\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 5s 84us/step - loss: 0.8882 - acc: 0.8505\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 5s 89us/step - loss: 0.8892 - acc: 0.8522\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 0.8828 - acc: 0.8529\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 5s 88us/step - loss: 0.8834 - acc: 0.8492\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.8760 - acc: 0.8507\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.8782 - acc: 0.8492\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 0.8748 - acc: 0.8483\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8776 - acc: 0.8445\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8757 - acc: 0.8477\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.8664 - acc: 0.8401\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8630 - acc: 0.8398\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8613 - acc: 0.8374\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8647 - acc: 0.8398\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8564 - acc: 0.8427\n",
      "70 0.47140028535641815 0.862261782499114\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 1.0058 - acc: 0.7737\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9425 - acc: 0.8119\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9205 - acc: 0.8245\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 0.9127 - acc: 0.8295\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9073 - acc: 0.8350\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 82us/step - loss: 0.9037 - acc: 0.8382\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9024 - acc: 0.8403\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9008 - acc: 0.8407\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8956 - acc: 0.8445\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8946 - acc: 0.8467\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8933 - acc: 0.8487\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8910 - acc: 0.8490\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8905 - acc: 0.8487\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8882 - acc: 0.8493\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8851 - acc: 0.8520\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8863 - acc: 0.8527\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.8822 - acc: 0.8583\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8803 - acc: 0.8504\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8782 - acc: 0.8469\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8782 - acc: 0.8485\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8736 - acc: 0.8495\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8725 - acc: 0.8414\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8756 - acc: 0.8437\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8685 - acc: 0.8443\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8692 - acc: 0.8397\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8709 - acc: 0.8350\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8645 - acc: 0.8333\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8585 - acc: 0.8296\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8604 - acc: 0.8356\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8657 - acc: 0.8334\n",
      "80 0.4190589155304758 0.8439651565338815\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 1.0292 - acc: 0.7756\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9590 - acc: 0.8094\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9429 - acc: 0.8182\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 5s 85us/step - loss: 0.9330 - acc: 0.8229\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.9270 - acc: 0.8292\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 79us/step - loss: 0.9200 - acc: 0.8349\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9191 - acc: 0.8336\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9172 - acc: 0.8370\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9113 - acc: 0.8374\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9096 - acc: 0.8411\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.9090 - acc: 0.8413\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 80us/step - loss: 0.9086 - acc: 0.8473\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9052 - acc: 0.8454\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9052 - acc: 0.8455\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9007 - acc: 0.8513\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9048 - acc: 0.8531\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8997 - acc: 0.8515\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9012 - acc: 0.8558\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8982 - acc: 0.8541\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8966 - acc: 0.8579\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8935 - acc: 0.8590\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8947 - acc: 0.8568\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8922 - acc: 0.8574\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8917 - acc: 0.8587\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8923 - acc: 0.8644\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8877 - acc: 0.8650\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 81us/step - loss: 0.8871 - acc: 0.8574\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 78us/step - loss: 0.8813 - acc: 0.8533\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8864 - acc: 0.8501\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8818 - acc: 0.8484\n",
      "90 0.4115874228880057 0.8793411693148925\n",
      "Epoch 1/30\n",
      "53373/53373 [==============================] - 4s 83us/step - loss: 1.0138 - acc: 0.7751\n",
      "Epoch 2/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9466 - acc: 0.8138\n",
      "Epoch 3/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9281 - acc: 0.8234\n",
      "Epoch 4/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9187 - acc: 0.8269\n",
      "Epoch 5/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.9132 - acc: 0.8329\n",
      "Epoch 6/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9056 - acc: 0.8333\n",
      "Epoch 7/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.9046 - acc: 0.8395\n",
      "Epoch 8/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8977 - acc: 0.8424\n",
      "Epoch 9/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8963 - acc: 0.8439\n",
      "Epoch 10/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8986 - acc: 0.8443\n",
      "Epoch 11/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8909 - acc: 0.8468\n",
      "Epoch 12/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8884 - acc: 0.8464\n",
      "Epoch 13/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8916 - acc: 0.8502\n",
      "Epoch 14/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8873 - acc: 0.8533\n",
      "Epoch 15/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8899 - acc: 0.8544\n",
      "Epoch 16/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8883 - acc: 0.8519\n",
      "Epoch 17/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8884 - acc: 0.8572\n",
      "Epoch 18/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8846 - acc: 0.8575\n",
      "Epoch 19/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8824 - acc: 0.8571\n",
      "Epoch 20/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8822 - acc: 0.8565\n",
      "Epoch 21/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8814 - acc: 0.8575\n",
      "Epoch 22/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8811 - acc: 0.8578\n",
      "Epoch 23/30\n",
      "53373/53373 [==============================] - 4s 77us/step - loss: 0.8821 - acc: 0.8614\n",
      "Epoch 24/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8782 - acc: 0.8653\n",
      "Epoch 25/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8727 - acc: 0.8620\n",
      "Epoch 26/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8750 - acc: 0.8601\n",
      "Epoch 27/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8682 - acc: 0.8587\n",
      "Epoch 28/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8714 - acc: 0.8544\n",
      "Epoch 29/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8746 - acc: 0.8530\n",
      "Epoch 30/30\n",
      "53373/53373 [==============================] - 4s 76us/step - loss: 0.8719 - acc: 0.8538\n",
      "100 0.4481813800392066 0.845600821645495\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFdJJREFUeJzt3X+wX3V95/HnSxSp1kqQ2wzNj4YdYxV1VPYO4rhaNW340Y5hphbj2vXKZJq1S7tt19kt7s5OWMBdHLd1ZdZis5I2MC2QQl0yypZmA467O4IEocgPWa78MMkCSUlMt2X9EfreP76f4Fea6/3e5Hu/X27O8zFz53vO53zO+Xw+JOR1z/mc7zmpKiRJ3fOicXdAkjQeBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHTVQACT57ST3J7kvybVJTkhyapI7kkwnuT7J8a3uS9v6dNu+ou84H2vlDyU5a36GJEkaxKwBkGQJ8M+Byap6A3AcsBb4BPCpqno1sB9Y13ZZB+xv5Z9q9UhyWtvv9cDZwO8nOW64w5EkDerFc6j3Y0m+D7wMeAJ4D/CP2/bNwMXAlcCatgxwA/Cfk6SVX1dV3wUeTTINnAF8ZaZGTz755FqxYsUchiNJuuuuu/6qqiZmqzdrAFTV7iT/EfgW8P+AvwDuAr5dVQdbtV3Akra8BNjZ9j2Y5ADwqlZ+e9+h+/d5TpL1wHqA5cuXs2PHjtm6KEnqk+TxQeoNcgloEb3f3k8Ffgp4Ob1LOPOiqjZW1WRVTU5MzBpgkqQjNMgk8M8Bj1bV3qr6PvBnwNuBE5McOoNYCuxuy7uBZQBt+yuBp/vLD7OPJGnEBgmAbwFnJnlZu5a/CngAuA14X6szBdzUlre2ddr2W6v3yNGtwNp2l9CpwErgq8MZhiRprgaZA7gjyQ3A14CDwN3ARuCLwHVJLmtlV7VdrgKuaZO8++jd+UNV3Z9kC73wOAhcWFXPDnk8kqQB5YX8PoDJyclyEliS5ibJXVU1OVs9vwksSR1lAEhSRxkAktRRBoAkddSgj4KQfqTfff8vjqXdj17/hbG0Kx0LPAOQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaO8DXQeXHzxxZ1qV9LCZADMg3e885oxtXzxmNqVtBB5CUiSOsozgGPIZz5y67i7IGkB8QxAkjrKAJCkjjIAJKmjZg2AJD+T5J6+n79O8ltJTkqyLcnD7XNRq58kVySZTnJvktP7jjXV6j+cZGrmViVJ823WAKiqh6rqzVX1ZuAfAs8AnwcuArZX1Upge1sHOAdY2X7WA1cCJDkJ2AC8FTgD2HAoNCRJozfXS0CrgG9W1ePAGmBzK98MnNeW1wBXV8/twIlJTgHOArZV1b6q2g9sA84+6hFIko7IXANgLXBtW15cVU+05SeBxW15CbCzb59drWymcknSGAwcAEmOB94L/Onzt1VVATWMDiVZn2RHkh179+4dxiElSYcxlzOAc4CvVdVTbf2pdmmH9rmnle8GlvXtt7SVzVT+Q6pqY1VNVtXkxMTEHLonSZqLuQTAB/jB5R+ArcChO3mmgJv6yj/U7gY6EzjQLhXdAqxOsqhN/q5uZZKkMRjoURBJXg78PPBP+4ovB7YkWQc8Dpzfym8GzgWm6d0xdAFAVe1LcilwZ6t3SVXtO+oRSJKOyEABUFV/C7zqeWVP07sr6Pl1C7hwhuNsAjbNvZuSpGHzYXDz4IO5cSzt/ls8oZI0OB8FIUkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUb4P4Bjy2vN/dWxt3/MHrxtb25KOjGcAktRRAwVAkhOT3JDkG0keTPK2JCcl2Zbk4fa5qNVNkiuSTCe5N8npfceZavUfTjI1c4uSpPk26BnAp4E/r6rXAm8CHgQuArZX1Upge1sHOAdY2X7WA1cCJDkJ2AC8FTgD2HAoNCRJozfrHECSVwLvBD4MUFXfA76XZA3wrlZtM/Al4HeANcDV7eXwt7ezh1Na3W1Vta8ddxtwNnDt8Ibzw964+Y3zdegfbfk142lXkuZgkDOAU4G9wB8muTvJ55K8HFhcVU+0Ok8Ci9vyEmBn3/67WtlM5ZKkMRgkAF4MnA5cWVVvAf6WH1zuAaD9tl/D6FCS9Ul2JNmxd+/eYRxSknQYgwTALmBXVd3R1m+gFwhPtUs7tM89bftuYFnf/ktb2UzlP6SqNlbVZFVNTkxMzGUskqQ5mDUAqupJYGeSn2lFq4AHgK3AoTt5poCb2vJW4EPtbqAzgQPtUtEtwOoki9rk7+pWJkkag0G/CPYbwB8nOR54BLiAXnhsSbIOeBw4v9W9GTgXmAaeaXWpqn1JLgXubPUuOTQhLEkavYECoKruASYPs2nVYeoWcOEMx9kEbJpLByVJ88NvAktSRxkAktRRBoAkdZRPA9VQfPIjl42l3Y+OpVXp2OAZgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FEGgCR1lAEgSR01UAAkeSzJ15Pck2RHKzspybYkD7fPRa08Sa5IMp3k3iSn9x1nqtV/OMnUTO1JkubfXM4A3l1Vb66qQ+8GvgjYXlUrge1tHeAcYGX7WQ9cCb3AADYAbwXOADYcCg1J0ugdzSWgNcDmtrwZOK+v/OrquR04MckpwFnAtqraV1X7gW3A2UfRviTpKAwaAAX8RZK7kqxvZYur6om2/CSwuC0vAXb27burlc1ULkkag0FfCfmPqmp3kp8EtiX5Rv/GqqokNYwOtYBZD7B8+fJhHFKSdBgDnQFU1e72uQf4PL1r+E+1Szu0zz2t+m5gWd/uS1vZTOXPb2tjVU1W1eTExMTcRiNJGtisAZDk5UlecWgZWA3cB2wFDt3JMwXc1Ja3Ah9qdwOdCRxol4puAVYnWdQmf1e3MknSGAxyCWgx8Pkkh+r/SVX9eZI7gS1J1gGPA+e3+jcD5wLTwDPABQBVtS/JpcCdrd4lVbVvaCORJM3JrAFQVY8AbzpM+dPAqsOUF3DhDMfaBGyaezclScPmN4ElqaMMAEnqKANAkjrKAJCkjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjhr0pfAL0pb/cHAs7b77yrE0K0lzckwHwPVr3z/uLmie7brof4yt7aWXv2NsbUvDMPAloCTHJbk7yRfa+qlJ7kgyneT6JMe38pe29em2fUXfMT7Wyh9KctawByNJGtxczgB+E3gQ+Im2/gngU1V1XZLPAuuAK9vn/qp6dZK1rd77k5wGrAVeD/wU8N+TvKaqnh3SWDrvg7lx3F2QtIAMdAaQZCnwC8Dn2nqA9wA3tCqbgfPa8pq2Ttu+qtVfA1xXVd+tqkeBaeCMYQxCkjR3g14C+k/AvwL+rq2/Cvh2VR2aZd0FLGnLS4CdAG37gVb/ufLD7CNJGrFZAyDJLwJ7ququEfSHJOuT7EiyY+/evaNoUpI6aZAzgLcD703yGHAdvUs/nwZOTHJoDmEpsLst7waWAbTtrwSe7i8/zD7PqaqNVTVZVZMTExNzHpAkaTCzBkBVfayqllbVCnqTuLdW1QeB24D3tWpTwE1teWtbp22/taqqla9tdwmdCqwEvjq0kUiS5uRovgfwO8B1SS4D7gauauVXAdckmQb20QsNqur+JFuAB4CDwIXeASRJ4zOnAKiqLwFfasuPcJi7eKrqO8Avz7D/x4GPz7WTkqTh81lAktRRBoAkdZQBIEkdZQBIUkcZAJLUUQaAJHWUASBJHWUASFJHGQCS1FHH9Cshdex7aPWHx9b2Ur45tralYfAMQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqqFkDIMkJSb6a5C+T3J/k37XyU5PckWQ6yfVJjm/lL23r0237ir5jfayVP5TkrPkalCRpdoOcAXwXeE9VvQl4M3B2kjOBTwCfqqpXA/uBda3+OmB/K/9Uq0eS0+i9IP71wNnA7yc5bpiDkSQNbtYAqJ6/aasvaT8FvAe4oZVvBs5ry2vaOm37qiRp5ddV1Xer6lFgmsO8VF6SNBoDzQEkOS7JPcAeYBvwTeDbVXWwVdkFLGnLS4CdAG37AeBV/eWH2UeSNGIDBUBVPVtVbwaW0vut/bXz1aEk65PsSLJj796989WMJHXenO4CqqpvA7cBbwNOTHLoaaJLgd1teTewDKBtfyXwdH/5Yfbpb2NjVU1W1eTExMRcuidJmoNB7gKaSHJiW/4x4OeBB+kFwftatSngpra8ta3Ttt9aVdXK17a7hE4FVgJfHdZAJElzM8j7AE4BNrc7dl4EbKmqLyR5ALguyWXA3cBVrf5VwDVJpoF99O78oaruT7IFeAA4CFxYVc8OdziSpEHNGgBVdS/wlsOUP8Jh7uKpqu8AvzzDsT4OfHzu3ZQkDZvfBJakjjIAJKmjDABJ6igDQJI6ygCQpI4yACSpowwASeooA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmjBnkfwIL12Z89b/ZKWtA+mBvH1vaTY2tZGg7PACSpowwASeooA0CSOmqQl8IvS3JbkgeS3J/kN1v5SUm2JXm4fS5q5UlyRZLpJPcmOb3vWFOt/sNJpmZqU5I0/wY5AzgIfLSqTgPOBC5MchpwEbC9qlYC29s6wDnAyvazHrgSeoEBbADeSu9dwhsOhYYkafRmDYCqeqKqvtaW/y/wILAEWANsbtU2A4duuVkDXF09twMnJjkFOAvYVlX7qmo/sA04e6ijkSQNbE5zAElWAG8B7gAWV9UTbdOTwOK2vATY2bfbrlY2U7kkaQwGDoAkPw7cCPxWVf11/7aqKqCG0aEk65PsSLJj7969wzikJOkwBgqAJC+h94//H1fVn7Xip9qlHdrnnla+G1jWt/vSVjZT+Q+pqo1VNVlVkxMTE3MZiyRpDmb9JnCSAFcBD1bV7/Vt2gpMAZe3z5v6yn89yXX0JnwPVNUTSW4B/n3fxO9q4GPDGYY0eg++9nVjafd133hwLO3q2DPIoyDeDvwT4OtJ7mll/5reP/xbkqwDHgfOb9tuBs4FpoFngAsAqmpfkkuBO1u9S6pq31BGIY3BK87bOO4uSEdl1gCoqv8JZIbNqw5Tv4ALZzjWJmDTXDooSZoffhNYkjrKAJCkjjIAJKmjjun3AUjz6XMnbB9LuxfzjrG0q2OPZwCS1FEGgCR1lAEgSR1lAEhSRzkJLB2hd7zzmjG1fPGY2tWxxgCQjtAHc+NY2n1yLK3qWGQASNIM3rj5jWNr++tTX5/3NpwDkKSO8gxAkmbw4Zt/enyNT81/EwaAJM3gkx+5bGxtf3QEbXgJSJI6ygCQpI4yACSpo5wDkBaYFRd9cWxtP3b5L4ytbQ3frGcASTYl2ZPkvr6yk5JsS/Jw+1zUypPkiiTTSe5NcnrfPlOt/sNJRjC/LUn6UQa5BPRHwNnPK7sI2F5VK4HtbR3gHGBl+1kPXAm9wAA2AG8FzgA2HAoNSdJ4zBoAVfVlYN/zitcAm9vyZuC8vvKrq+d24MQkpwBnAduqal9V7Qe28fdDRZI0Qkc6B7C4qp5oy08Ci9vyEmBnX71drWymckkLyLjmH5x7mB9HPQlcVZWkhtEZgCTr6V0+Yvny5cM6rHTM+M5Z4/vd6YRbdo+tbQ3fkd4G+lS7tEP73NPKdwPL+uotbWUzlf89VbWxqiaranJiYuIIuydJms2RBsBWfvCkiingpr7yD7W7gc4EDrRLRbcAq5MsapO/q1uZJGlMZr0ElORa4F3AyUl20bub53JgS5J1wOPA+a36zcC5wDTwDHABQFXtS3IpcGerd0lVPX9iWZI0QrMGQFV9YIZNqw5Tt4ALZzjOJmDTnHon6QXlFa+7aPZK88JJ4PngoyAkqaN8FISkge1dPq73IGs+GACSXvDG9mrGYzzwvAQkSR1lAEhSRxkAktRRBoAkdZSTwJJe8D7ylU+Ppd1Lj/HHkRkAkl7wLn3/SePuwjHJS0CS1FEGgCR1lAEgSR1lAEhSRxkAktRRBoAkdZQBIEkdZQBIUkcZAJLUUSMPgCRnJ3koyXSScb1fTpI6b6QBkOQ44DPAOcBpwAeSnDbKPkiSekZ9BnAGMF1Vj1TV94DrgDUj7oMkidEHwBJgZ9/6rlYmSRqxF9zTQJOsB9a31b9J8tBRHO5k4K+OvlcLRtfGC465Kzo35hzdmH96kEqjDoDdwLK+9aWt7DlVtRHYOIzGkuyoqslhHGsh6Np4wTF3hWOeH6O+BHQnsDLJqUmOB9YCW0fcB0kSIz4DqKqDSX4duAU4DthUVfePsg+SpJ6RzwFU1c3AzSNqbiiXkhaQro0XHHNXOOZ5kKqa7zYkSS9APgpCkjpqwQfAbI+WSPLSJNe37XckWTH6Xg7XAGP+F0keSHJvku1JBrol7IVs0EeIJPmlJJVkwd8xMsiYk5zf/qzvT/Ino+7jsA3wd3t5ktuS3N3+fp87jn4OS5JNSfYkuW+G7UlyRfvvcW+S04fagapasD/0JpK/CfwD4HjgL4HTnlfnnwGfbctrgevH3e8RjPndwMva8q91Ycyt3iuALwO3A5Pj7vcI/pxXAncDi9r6T4673yMY80bg19ryacBj4+73UY75ncDpwH0zbD8X+G9AgDOBO4bZ/kI/Axjk0RJrgM1t+QZgVZKMsI/DNuuYq+q2qnqmrd5O7/sWC9mgjxC5FPgE8J1Rdm6eDDLmXwU+U1X7Aapqz4j7OGyDjLmAn2jLrwT+zwj7N3RV9WVg34+osga4unpuB05Mcsqw2l/oATDIoyWeq1NVB4EDwKtG0rv5MdfHaayj9xvEQjbrmNup8bKq+uIoOzaPBvlzfg3wmiT/K8ntSc4eWe/mxyBjvhj4lSS76N1N+Buj6drYzOvjc15wj4LQ8CT5FWAS+Nlx92U+JXkR8HvAh8fclVF7Mb3LQO+id5b35SRvrKpvj7VX8+sDwB9V1e8meRtwTZI3VNXfjbtjC9FCPwOY9dES/XWSvJjeaePTI+nd/BhkzCT5OeDfAO+tqu+OqG/zZbYxvwJ4A/ClJI/Ru1a6dYFPBA/y57wL2FpV36+qR4H/TS8QFqpBxrwO2AJQVV8BTqD3zJxj1UD/vx+phR4AgzxaYisw1ZbfB9xabXZlgZp1zEneAvwBvX/8F/p1YZhlzFV1oKpOrqoVVbWC3rzHe6tqx3i6OxSD/N3+r/R++yfJyfQuCT0yyk4O2SBj/hawCiDJ6+gFwN6R9nK0tgIfancDnQkcqKonhnXwBX0JqGZ4tESSS4AdVbUVuIreaeI0vcmWtePr8dEbcMyfBH4c+NM23/2tqnrv2Dp9lAYc8zFlwDHfAqxO8gDwLPAvq2rBnt0OOOaPAv8lyW/TmxD+8EL+hS7JtfRC/OQ2r7EBeAlAVX2W3jzHucA08AxwwVDbX8D/7SRJR2GhXwKSJB0hA0CSOsoAkKSOMgAkqaMMAEnqKANAkjrKAJCkjjIAJKmj/j8AolgLVlqQRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for random_state in [10,20,30,40,50,60,70,80,90,100]:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(spec_matrix_db, np.array(y), test_size=0.33,\n",
    "                                                        random_state=random_state)\n",
    "    # Normalise by statistics of training data\n",
    "    X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "    X_test_norm = (X_test - np.mean(X_train))/np.std(X_train)\n",
    "    X_train_tf = X_train_norm.reshape(X_train_norm.shape[0], 1, X_train_norm.shape[1], X_train_norm.shape[2])\n",
    "    X_test_tf = X_test_norm.reshape(X_test_norm.shape[0], 1, X_test_norm.shape[1], X_test_norm.shape[2])\n",
    "\n",
    "    ################################ CONVOLUTIONAL NEURAL NETWORK ################################\n",
    "    ## NN parameters\n",
    "    class_weight = {0: 1.,\n",
    "                    1: 10.,\n",
    "                    }\n",
    "    input_shape = (1, X_train_tf.shape[2], X_train_tf.shape[-1])\n",
    "\n",
    "    model = Sequential()\n",
    "    n_dense = 128\n",
    "    nb_classes = 2\n",
    "    # number of convolutional filters\n",
    "    nb_conv_filters = 32\n",
    "    # num_hidden = 236\n",
    "    nb_conv_filters_2 = 64\n",
    "    convout1 = Activation('relu')\n",
    "    convout2 = Activation('relu')\n",
    "\n",
    "    model.add(Conv2D(nb_conv_filters, kernel_size = (3,3),\n",
    "         activation = 'relu', padding = 'valid', strides = 1,\n",
    "         input_shape = input_shape))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(nb_conv_filters_2, kernel_size = (3,3),\n",
    "         activation = 'relu', padding = 'valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # model.add(Conv2D(nb_conv_filters_2, kernel_size = (5,5),\n",
    "    #      activation = 'relu', padding = 'valid'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.2))  \n",
    "    model.add(Flatten())\n",
    "    # Shared between MLP and CNN:\n",
    "    model.add(Dense(n_dense, activation='relu'))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adadelta',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=X_train_tf, y=y_train, batch_size=None, epochs=30, verbose=1, callbacks=None, validation_split=0.0,\n",
    "              validation_data=None,\n",
    "              shuffle=True, class_weight=class_weight, sample_weight=None, initial_epoch=0,\n",
    "              steps_per_epoch=None, validation_steps=None)\n",
    "\n",
    "\n",
    "    loss, acc = model.evaluate(x=X_test_tf, y=y_test, batch_size=None, verbose=0, sample_weight=None, steps=None)\n",
    "    pred = model.predict(X_test_tf)\n",
    "    plt.hist(pred[:,1]) # Optional: visualise histogram of labels\n",
    "#     plt.show()\n",
    "    print(random_state, loss, acc)\n",
    "    \n",
    "    pred_list.append(pred)  # Collect y_test to report classification performance\n",
    "    y_test_list.append(y_test)  # Collect y_test to report classification performance\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, std,\n",
    "                          normalize=False,\n",
    "                                                    cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    std = std * 100\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] *100\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt) + ' ± ' + format(std[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "cm_list = []\n",
    "for i in np.arange(len(pred_list)):\n",
    "        cm_list.append(confusion_matrix(np.argmax(y_test_list[i],-1), np.argmax(pred_list[i],-1)))\n",
    "cm_mean = np.mean(cm_list, axis = 0)\n",
    "total = np.sum(cm_mean)\n",
    "cm_mean = cm_mean/total\n",
    "cm_std = np.std(cm_list, axis = 0)/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and display plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[87.3  12.7 ]\n",
      " [32.08 67.92]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ikiskin/anaconda3/envs/tensorflow/lib/python3.6/site-packages/matplotlib/font_manager.py:1328: UserWarning: findfont: Font family ['normal'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "class_names= np.array(['Noise', 'Mozz'])\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(cm_mean, std=cm_std, classes=class_names, normalize=True)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('Confusion_matrix_w_1_5_0_30_epochs_not_sure_into_yes_single_0_5_multi_no_overlap_1second.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
